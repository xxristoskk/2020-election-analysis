{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Primary Election Twitter Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraped close to 482,000 Tweets about three candidates who were predicted to lead, along with tweets about the Iowa caucuses, for data exploration and analysis. Tweets were collected by Twint, running get_tweets.py daily, which saves the results in a pickle file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More EDA with TF-IDF vectorization\n",
    "### Tokenizing, creating a bag of words, and determing the frequency of words and assigning weight to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('cleanDf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455952, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = p1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = p2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xristos/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([p1,p2,df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484752, 39)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "484752it [03:04, 2632.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By talking unions/livable wages for ALL. Puhlease.\n"
     ]
    }
   ],
   "source": [
    "## after investigating the tweets some more, there were \"pic.twitter\" links\n",
    "for i, row in tqdm(df.iterrows()):\n",
    "    df.at[i,'tweet'] = re.sub(\"(pic.twitter.com)+\\/.+\",'',row['tweet'])\n",
    "    \n",
    "print(df.tweet[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle('cleanDf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc9a374a8d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAGRCAYAAAA+WCQ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAe6klEQVR4nO3df7RdZX3n8feniaj1FyiRUiAGnVQHqEZJkanVUawYsG2wRSWrU6JlVsRCO51V14jTH7CsdLAudY2t4mDJEFrLj4qWzBiLlNJiW0GCxAAKk2tEiGT4aZEWhUn8zh/nufUQ7s0N995wnty8X2uddc7+7mfv8z2suw6f7Gfvs1NVSJIkqS8/MuoGJEmS9HiGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOzR91A7Nt//33r0WLFo26DUmSpCndcMMN91XVgonWzbmQtmjRItavXz/qNiRJkqaU5FuTrXO6U5IkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA7NH3UDkvYui8743Khb2Ovcfs6bRt2CpGnwSJokSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR2aMqQlWZ3kniQ3D9UuSbKhPW5PsqHVFyX53tC6Twxtc2SSm5KMJflokrT6c5NcmWRTe96v1dPGjSXZmOQVs//xJUmS+rQrR9IuAJYNF6rqbVW1pKqWAJcBnxla/Y3xdVV16lD9XGAVsLg9xvd5BnBVVS0GrmrLAMcNjV3VtpckSdorTBnSquoa4IGJ1rWjYW8FLtrZPpIcCDy7qr5UVQVcCJzQVi8H1rTXa3aoX1gD1wL7tv1IkiTNeTM9J+3VwN1VtWmodmiSG5P8XZJXt9pBwJahMVtaDeCAqtoK0J6fP7TNnZNsI0mSNKfNn+H2K3jsUbStwMKquj/JkcBfJjkcyATb1hT73uVtkqxiMCXKwoULp2xakiSpd9M+kpZkPvCLwCXjtap6pKrub69vAL4B/ASDo2AHD21+MHBXe333+DRme76n1bcAh0yyzWNU1XlVtbSqli5YsGC6H0mSJKkbM5nu/Fng1qr612nMJAuSzGuvX8jgpP/NbRrzoSRHt/PYTgYub5utBVa21yt3qJ/crvI8GnhwfFpUkiRprtuVn+C4CPgS8OIkW5Kc0ladxOMvGHgNsDHJV4FPA6dW1fhFB+8C/gQYY3CE7fOtfg7whiSbgDe0ZYB1wOY2/pPArz3xjydJkrRnmvKctKpaMUn97RPULmPwkxwTjV8PHDFB/X7g9RPUCzhtqv4kSZLmIu84IEmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUoSlDWpLVSe5JcvNQ7awk306yoT2OH1r33iRjSW5L8sah+rJWG0tyxlD90CTXJdmU5JIk+7T6U9vyWFu/aLY+tCRJUu925UjaBcCyCeofqaol7bEOIMlhwEnA4W2bjyeZl2Qe8DHgOOAwYEUbC/CBtq/FwHeAU1r9FOA7VfVvgI+0cZIkSXuFKUNaVV0DPLCL+1sOXFxVj1TVN4Ex4Kj2GKuqzVX1KHAxsDxJgGOAT7ft1wAnDO1rTXv9aeD1bbwkSdKcN5Nz0k5PsrFNh+7XagcBdw6N2dJqk9WfB/xTVW3bof6YfbX1D7bxkiRJc950Q9q5wIuAJcBW4EOtPtGRrppGfWf7epwkq5KsT7L+3nvv3VnfkiRJe4RphbSquruqtlfVD4BPMpjOhMGRsEOGhh4M3LWT+n3Avknm71B/zL7a+ucwybRrVZ1XVUuraumCBQum85EkSZK6Mq2QluTAocU3A+NXfq4FTmpXZh4KLAa+DFwPLG5Xcu7D4OKCtVVVwNXAiW37lcDlQ/ta2V6fCPxNGy9JkjTnzZ9qQJKLgNcC+yfZApwJvDbJEgbTj7cD7wSoqluSXAp8DdgGnFZV29t+TgeuAOYBq6vqlvYW7wEuTvJ+4Ebg/FY/H/jTJGMMjqCdNONPK0mStIeYMqRV1YoJyudPUBsffzZw9gT1dcC6Ceqb+eF06XD9+8BbpupPkiRpLvKOA5IkSR0ypEmSJHVoyulOPXkWnfG5Ubew17n9nDeNugVJkibkkTRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOjRlSEuyOsk9SW4eqn0wya1JNib5bJJ9W31Rku8l2dAenxja5sgkNyUZS/LRJGn15ya5Msmm9rxfq6eNG2vv84rZ//iSJEl92pUjaRcAy3aoXQkcUVUvBf4P8N6hdd+oqiXtcepQ/VxgFbC4Pcb3eQZwVVUtBq5qywDHDY1d1baXJEnaK0wZ0qrqGuCBHWpfqKptbfFa4OCd7SPJgcCzq+pLVVXAhcAJbfVyYE17vWaH+oU1cC2wb9uPJEnSnDd/Fvbxq8AlQ8uHJrkR+C7wO1X1ReAgYMvQmC2tBnBAVW0FqKqtSZ7f6gcBd06wzdZZ6FmSpN1m0RmfG3ULe53bz3nTqFuYdTMKaUl+G9gGfKqVtgILq+r+JEcCf5nkcCATbF5T7X5Xt0myisGUKAsXLtyV1iVJkro27as7k6wEfg745TaFSVU9UlX3t9c3AN8AfoLBUbDhKdGDgbva67vHpzHb8z2tvgU4ZJJtHqOqzquqpVW1dMGCBdP9SJIkSd2YVkhLsgx4D/ALVfXwUH1Bknnt9QsZnPS/uU1nPpTk6HZV58nA5W2ztcDK9nrlDvWT21WeRwMPjk+LSpIkzXVTTncmuQh4LbB/ki3AmQyu5nwqcGX7JY1r25WcrwHel2QbsB04tarGLzp4F4MrRZ8OfL49AM4BLk1yCnAH8JZWXwccD4wBDwPvmMkHlSRJ2pNMGdKqasUE5fMnGXsZcNkk69YDR0xQvx94/QT1Ak6bqj9JkqS5yDsOSJIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUoV0KaUlWJ7knyc1DtecmuTLJpva8X6snyUeTjCXZmOQVQ9usbOM3JVk5VD8yyU1tm48myc7eQ5Ikaa7b1SNpFwDLdqidAVxVVYuBq9oywHHA4vZYBZwLg8AFnAm8EjgKOHModJ3bxo5vt2yK95AkSZrTdimkVdU1wAM7lJcDa9rrNcAJQ/ULa+BaYN8kBwJvBK6sqgeq6jvAlcCytu7ZVfWlqirgwh32NdF7SJIkzWkzOSftgKraCtCen9/qBwF3Do3b0mo7q2+ZoL6z93iMJKuSrE+y/t57753BR5IkSerD7rhwIBPUahr1XVZV51XV0qpaumDBgieyqSRJUpdmEtLublOVtOd7Wn0LcMjQuIOBu6aoHzxBfWfvIUmSNKfNJKStBcav0FwJXD5UP7ld5Xk08GCbqrwCODbJfu2CgWOBK9q6h5Ic3a7qPHmHfU30HpIkSXPa/F0ZlOQi4LXA/km2MLhK8xzg0iSnAHcAb2nD1wHHA2PAw8A7AKrqgSS/D1zfxr2vqsYvRngXgytInw58vj3YyXtIkiTNabsU0qpqxSSrXj/B2AJOm2Q/q4HVE9TXA0dMUL9/oveQJEma67zjgCRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElSh6Yd0pK8OMmGocd3k/xmkrOSfHuofvzQNu9NMpbktiRvHKova7WxJGcM1Q9Ncl2STUkuSbLP9D+qJEnSnmPaIa2qbquqJVW1BDgSeBj4bFv9kfF1VbUOIMlhwEnA4cAy4ONJ5iWZB3wMOA44DFjRxgJ8oO1rMfAd4JTp9itJkrQnma3pztcD36iqb+1kzHLg4qp6pKq+CYwBR7XHWFVtrqpHgYuB5UkCHAN8um2/BjhhlvqVJEnq2myFtJOAi4aWT0+yMcnqJPu12kHAnUNjtrTaZPXnAf9UVdt2qEuSJM15Mw5p7TyxXwD+opXOBV4ELAG2Ah8aHzrB5jWN+kQ9rEqyPsn6e++99wl0L0mS1KfZOJJ2HPCVqroboKrurqrtVfUD4JMMpjNhcCTskKHtDgbu2kn9PmDfJPN3qD9OVZ1XVUuraumCBQtm4SNJkiSN1myEtBUMTXUmOXBo3ZuBm9vrtcBJSZ6a5FBgMfBl4HpgcbuScx8GU6drq6qAq4ET2/YrgctnoV9JkqTuzZ96yOSS/CjwBuCdQ+U/TLKEwdTk7ePrquqWJJcCXwO2AadV1fa2n9OBK4B5wOqquqXt6z3AxUneD9wInD+TfiVJkvYUMwppVfUwgxP8h2u/spPxZwNnT1BfB6yboL6ZH06XSpIk7TW844AkSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUodmHNKS3J7kpiQbkqxvtecmuTLJpva8X6snyUeTjCXZmOQVQ/tZ2cZvSrJyqH5k2/9Y2zYz7VmSJKl3s3Uk7XVVtaSqlrblM4CrqmoxcFVbBjgOWNweq4BzYRDqgDOBVwJHAWeOB7s2ZtXQdstmqWdJkqRu7a7pzuXAmvZ6DXDCUP3CGrgW2DfJgcAbgSur6oGq+g5wJbCsrXt2VX2pqgq4cGhfkiRJc9ZshLQCvpDkhiSrWu2AqtoK0J6f3+oHAXcObbul1XZW3zJBXZIkaU6bPwv7eFVV3ZXk+cCVSW7dydiJzieradQfu9NBOFwFsHDhwqk7liRJ6tyMj6RV1V3t+R7gswzOKbu7TVXSnu9pw7cAhwxtfjBw1xT1gyeo79jDeVW1tKqWLliwYKYfSZIkaeRmFNKSPCPJs8ZfA8cCNwNrgfErNFcCl7fXa4GT21WeRwMPtunQK4Bjk+zXLhg4FriirXsoydHtqs6Th/YlSZI0Z810uvMA4LPtVzHmA39eVX+V5Hrg0iSnAHcAb2nj1wHHA2PAw8A7AKrqgSS/D1zfxr2vqh5or98FXAA8Hfh8e0iSJM1pMwppVbUZeNkE9fuB109QL+C0Sfa1Glg9QX09cMRM+pQkSdrTeMcBSZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOTTukJTkkydVJvp7kliT/qdXPSvLtJBva4/ihbd6bZCzJbUneOFRf1mpjSc4Yqh+a5Lokm5JckmSf6fYrSZK0J5nJkbRtwG9V1b8FjgZOS3JYW/eRqlrSHusA2rqTgMOBZcDHk8xLMg/4GHAccBiwYmg/H2j7Wgx8BzhlBv1KkiTtMaYd0qpqa1V9pb1+CPg6cNBONlkOXFxVj1TVN4Ex4Kj2GKuqzVX1KHAxsDxJgGOAT7ft1wAnTLdfSZKkPcmsnJOWZBHwcuC6Vjo9ycYkq5Ps12oHAXcObbal1SarPw/4p6ratkNdkiRpzptxSEvyTOAy4Der6rvAucCLgCXAVuBD40Mn2LymUZ+oh1VJ1idZf++99z7BTyBJktSfGYW0JE9hENA+VVWfAaiqu6tqe1X9APgkg+lMGBwJO2Ro84OBu3ZSvw/YN8n8HeqPU1XnVdXSqlq6YMGCmXwkSZKkLszk6s4A5wNfr6oPD9UPHBr2ZuDm9notcFKSpyY5FFgMfBm4HljcruTch8HFBWurqoCrgRPb9iuBy6fbryRJ0p5k/tRDJvUq4FeAm5JsaLX/yuDqzCUMpiZvB94JUFW3JLkU+BqDK0NPq6rtAElOB64A5gGrq+qWtr/3ABcneT9wI4NQKEmSNOdNO6RV1d8z8Xlj63ayzdnA2RPU1020XVVt5ofTpZIkSXsN7zggSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktSh7kNakmVJbksyluSMUfcjSZL0ZOg6pCWZB3wMOA44DFiR5LDRdiVJkrT7dR3SgKOAsaraXFWPAhcDy0fckyRJ0m7Xe0g7CLhzaHlLq0mSJM1p80fdwBQyQa0eNyhZBaxqi/+c5Lbd2pV2tD9w36ibmI58YNQdaA/i37n2Bv6dP/leMNmK3kPaFuCQoeWDgbt2HFRV5wHnPVlN6bGSrK+qpaPuQ9qd/DvX3sC/8770Pt15PbA4yaFJ9gFOAtaOuCdJkqTdrusjaVW1LcnpwBXAPGB1Vd0y4rYkSZJ2u65DGkBVrQPWjboP7ZRTzdob+HeuvYF/5x1J1ePOw5ckSdKI9X5OmiRJ0l7JkCZJktQhQ5okSVKHur9wQP1q91Y9gKG/o6q6Y3QdSbtPkh8BnllV3x11L9Js8ru8X4Y0TUuSXwfOBO4GftDKBbx0ZE1JsyzJnwOnAtuBG4DnJPlwVX1wtJ1Js8Pv8r55daemJckY8Mqqun/UvUi7S5INVbUkyS8DRwLvAW6oKv8HpjnB7/K+eU6aputO4MFRNyHtZk9J8hTgBODyqvp/THD/YGkP5nd5x5zu1HRtBv42yeeAR8aLVfXh0bUkzbpPALcDXwWuSfICwHPSNJf4Xd4xQ5qm64722Kc9pDmlXShwd1UdNFS7A3jd6LqSZp3f5R3znDTNSJJnVNW/jLoPaXdIck1VvWbUfUi7m9/lffKcNE1Lkn+X5GvA19vyy5J8fMRtSbPtyiTvTnJIkueOP0bdlDRb/C7vm0fSNC1JrgNOBNZW1ctb7eaqOmK0nUmzJ8k3JyhXVb3wSW9G2g38Lu+b56Rp2qrqziTDpe2j6kXaHarq0FH3IO1ufpf3y+lOTdedSX4aqCT7JHk37XC5NFck+dEkv5PkvLa8OMnPjbovaRb5Xd4xQ5qm61TgNOAgYAuwpC1Lc8n/BB4FfrotbwHeP7p2pFnnd3nHnO7UtFTVfcAvj7oPaTd7UVW9LckKgKr6XnaYF5L2VO2enb9SVX6Xd8qQpickyR+xk19cr6rfeBLbkXa3R5M8nfY3n+RFDP3gp7Qnq6rtSZYDHxl1L5qYIU1P1Pr2/CrgMOCStvwWBjegluaSM4G/Ag5J8ikGf/dvH2lH0uz6hyR/zOC7/F9/J62qvjK6ljTOn+DQtCS5Gji23cuQdn/DL1SVv8auOSXJ84CjgQDXtql+aU5o3+U7qqo65klvRo/jkTRN148DzwIeaMvPbDVpj5fkFTuUtrbnhUkWepRBc0G79dm5VXXpqHvRxAxpmq5zgBuH/hX274GzRteONKs+1J6fBixlcIP1AC8FrgN+ZkR9SbOmqn6Q5HTAkNYppzs1bUl+DHhlW7yuqv7vKPuRZluSi4Gzq+qmtnwE8O6qevtIG5NmSZLfBb7H489Je2DSjfSkMaTpCUnykqq6dYLpIMCTTTW3JNlQVUumqkl7Km991jdDmp6QJOdV1ao2zTn8xxM82VRzTJKLGBxd+DMGf+//AXhmVa0YaWOS9gqGNE1L++2oX2Nwbk4BX2RwAur3R9qYNIuSPA14F/CaVroG/841x7Rp/MMYnIMJQFVdOLqONM6QpmlJcinwXeBTrbQC2Leq3jq6riRJT0SSM4HXMghp64DjgL+vqhNH2ZcGDGmaliRfraqXTVWT9mRJXsXgquUXMHQ1vOfraK5IchPwMuDGqnpZkgOAP6mqnx9xa8Kf4ND03Zjk6Kq6FiDJK4F/GHFP0mw7H/jPDO6msX3EvUi7w/fbT3FsS/Js4B7Af4R0wpCmJ6T9q6uApwAnJ7mjLb8A+Nooe5N2gwer6vOjbkLaja5Psi/wSQb/GPln4MujbUnjnO7UE5LkBTtbX1XferJ6kXa3JOcA84DPMHRjdX9qRnNFkj9lcEHMF4HvA8+uqo2j7UrjDGmSNAnva6i5LskxDK7SfzWDac4NwDVV9d9H2pgAQ5okSXu1JPOAnwJeB5wKfK+qXjLargSekyZJO5XkTcDhPPY3pN43uo6k2ZPkKuAZwJcYTHn+VFXdM9quNO5HRt2AJPUqySeAtwG/zuCuGm9hcJGMNFdsBB4FjgBeChzRfqxcHXC6U5ImkWRjVb106PmZwGeq6thR9ybNpva3/Q7g3cCPVdVTR9yScLpTknZm/PZPDyf5ceAB4NAR9iPNqiSnM7ho4EjgW8BqBtOe6oAhTZIm97/ab0h9EPgKg98E/ORoW5Jm1dOBDwM3VNW2UTejxzKkSdLkbgW2V9VlSQ4DXgH85Yh7kmZNVX1w1D1ocl44IEmT+92qeijJzwBvAC4Azh1tS5L2FoY0SZrc+P063wR8oqouB/YZYT+S9iKGNEma3LeT/A/grcC6JE/F701JTxJ/gkOSJpHkR4FlwE1VtSnJgcBPVtUXRtyapL2AIU2SJKlDHraXJEnqkCFNkiSpQ4Y0SZpEkrOSvLu9fl+Sn51gzGuT/O8p9rMkyfG7q09Jc5M/ZitJu6Cqfm8Gmy8BlgLrZqkdSXsBj6RJmjOSnJxkY5KvJvnTJD+f5LokNyb56yQHtHFnJVmd5G+TbE7yG0P7+O0ktyX5a+DFQ/ULkpzYXi9LcmuSvwd+cWjMUUn+sb3fPyZ5cZJ9gPcBb0uyIcnbkjyjvf/1bezyJ+u/kaQ9h0fSJM0JSQ4Hfht4VVXdl+S5DO61eXRVVZL/CPwX4LfaJi8BXgc8C7gtybnAS4GTgJcz+H78CnDDDu/zNAb37zwGGAMuGVp9K/CaqtrWpkb/oKp+KcnvAUur6vS2jz8A/qaqfrXdG/TLSf66qv5ltv+7SNpzGdIkzRXHAJ+uqvsAquqBJD8JXNJ+32wf4JtD4z9XVY8AjyS5BzgAeDXw2ap6GCDJ2gne5yXAN6tqUxvzZ8Cqtu45wJokixkExKdM0uuxwC+Mn+8GPA1YCHx9Gp9b0hzldKekuSIMgtGwPwL+uKp+EngngzA07pGh19v54T9ad+XHIycb8/vA1VV1BPDzO7zfjr3+UlUtaY+FVWVAk/QYhjRJc8VVwFuTPA+gTXc+B/h2W79yF/ZxDfDmJE9P8iwGQWtHtwKHJnlRW14xtG74/d4+VH+IwbTquCuAX0+S1uvLd6E3SXsZQ5qkOaGqbgHOBv4uyVeBDwNnAX+R5IvAfbuwj68wOMdsA3AZ8MUJxnyfwfTm59qFA98aWv2HwH9L8g/AvKH61cBh4xcOMDji9hRgY5Kb27IkPYa3hZIkSeqQR9IkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA79fxz9VJgLCiL8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### distribution of tweets\n",
    "df.groupby(['candidate'])['tweet'].count().plot(kind='bar',figsize=(10,6))\n",
    "# plt.savefig('dist-tweets.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>ratio</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>4.559520e+05</td>\n",
       "      <td>455952.000000</td>\n",
       "      <td>455952.000000</td>\n",
       "      <td>455952.000000</td>\n",
       "      <td>455952.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>7.708949e+02</td>\n",
       "      <td>54.302902</td>\n",
       "      <td>215.354382</td>\n",
       "      <td>0.117852</td>\n",
       "      <td>0.050909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>5.940889e+03</td>\n",
       "      <td>466.304908</td>\n",
       "      <td>1720.854199</td>\n",
       "      <td>0.306633</td>\n",
       "      <td>0.485201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>-0.304900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.040741</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.260000e+02</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>0.105504</td>\n",
       "      <td>0.440400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.911685e+06</td>\n",
       "      <td>93013.000000</td>\n",
       "      <td>460432.000000</td>\n",
       "      <td>34.195122</td>\n",
       "      <td>0.999500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              likes        replies       retweets          ratio  \\\n",
       "count  4.559520e+05  455952.000000  455952.000000  455952.000000   \n",
       "mean   7.708949e+02      54.302902     215.354382       0.117852   \n",
       "std    5.940889e+03     466.304908    1720.854199       0.306633   \n",
       "min    0.000000e+00       0.000000       0.000000       0.000000   \n",
       "25%    1.100000e+01       1.000000       1.000000       0.006791   \n",
       "50%    1.120000e+02       5.000000      19.000000       0.040741   \n",
       "75%    3.260000e+02      21.000000      93.000000       0.105504   \n",
       "max    1.911685e+06   93013.000000  460432.000000      34.195122   \n",
       "\n",
       "           sentiment  \n",
       "count  455952.000000  \n",
       "mean        0.050909  \n",
       "std         0.485201  \n",
       "min        -0.999500  \n",
       "25%        -0.304900  \n",
       "50%         0.000000  \n",
       "75%         0.440400  \n",
       "max         0.999500  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113318, 15)\n",
      "(341814, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df[df.retweets>93].shape)\n",
    "print(df[df.retweets<93].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>timezone</th>\n",
       "      <th>tweet</th>\n",
       "      <th>user_id_str</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>search</th>\n",
       "      <th>near</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>candidate</th>\n",
       "      <th>ratio</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1217957258467979265</td>\n",
       "      <td>2020-01-16 18:50:13</td>\n",
       "      <td>EST</td>\n",
       "      <td>Still talking about the Warren fib/lie/misunde...</td>\n",
       "      <td>20479813</td>\n",
       "      <td>534</td>\n",
       "      <td>107</td>\n",
       "      <td>114</td>\n",
       "      <td>joe biden</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>biden</td>\n",
       "      <td>0.200375</td>\n",
       "      <td>-0.5610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1217948461443747840</td>\n",
       "      <td>2020-01-16 18:15:16</td>\n",
       "      <td>EST</td>\n",
       "      <td>Trump &amp; Giuliani attempted to manufacture an i...</td>\n",
       "      <td>18382184</td>\n",
       "      <td>690</td>\n",
       "      <td>17</td>\n",
       "      <td>175</td>\n",
       "      <td>joe biden</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>biden</td>\n",
       "      <td>0.024638</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1217947245955383296</td>\n",
       "      <td>2020-01-16 18:10:26</td>\n",
       "      <td>EST</td>\n",
       "      <td>BREAKING: \"Coup Update: Senate must let Presid...</td>\n",
       "      <td>18247062</td>\n",
       "      <td>1028</td>\n",
       "      <td>36</td>\n",
       "      <td>454</td>\n",
       "      <td>joe biden</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>biden</td>\n",
       "      <td>0.035019</td>\n",
       "      <td>-0.4926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1217947054850310145</td>\n",
       "      <td>2020-01-16 18:09:40</td>\n",
       "      <td>EST</td>\n",
       "      <td>Dear USA,     We dont like your President, can...</td>\n",
       "      <td>824472044913983488</td>\n",
       "      <td>215</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>joe biden</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>biden</td>\n",
       "      <td>0.027907</td>\n",
       "      <td>0.2686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1217944574951329795</td>\n",
       "      <td>2020-01-16 17:59:49</td>\n",
       "      <td>EST</td>\n",
       "      <td>New: It looks like Ihor Kolomoisky used Lev Pa...</td>\n",
       "      <td>1489840663</td>\n",
       "      <td>257</td>\n",
       "      <td>9</td>\n",
       "      <td>153</td>\n",
       "      <td>joe biden</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>biden</td>\n",
       "      <td>0.035019</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1217943813118926849</td>\n",
       "      <td>2020-01-16 17:56:48</td>\n",
       "      <td>EST</td>\n",
       "      <td>\"Is She (Pelosi) trying to payback President @...</td>\n",
       "      <td>56561449</td>\n",
       "      <td>2826</td>\n",
       "      <td>219</td>\n",
       "      <td>896</td>\n",
       "      <td>joe biden</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>biden</td>\n",
       "      <td>0.077495</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1217943377674743808</td>\n",
       "      <td>2020-01-16 17:55:04</td>\n",
       "      <td>EST</td>\n",
       "      <td>Harris on Biden Testifying 👇  …</td>\n",
       "      <td>41634520</td>\n",
       "      <td>575</td>\n",
       "      <td>268</td>\n",
       "      <td>189</td>\n",
       "      <td>joe biden</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>biden</td>\n",
       "      <td>0.466087</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1217942504110202883</td>\n",
       "      <td>2020-01-16 17:51:35</td>\n",
       "      <td>EST</td>\n",
       "      <td>Warren and Biden both backed it.Schumer Praise...</td>\n",
       "      <td>829715365223682048</td>\n",
       "      <td>381</td>\n",
       "      <td>12</td>\n",
       "      <td>107</td>\n",
       "      <td>joe biden</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>biden</td>\n",
       "      <td>0.031496</td>\n",
       "      <td>-0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>1217942314934554624</td>\n",
       "      <td>2020-01-16 17:50:50</td>\n",
       "      <td>EST</td>\n",
       "      <td>Today its Ukraine , GAO , Parmas , Giuliani , ...</td>\n",
       "      <td>1083551928821448710</td>\n",
       "      <td>270</td>\n",
       "      <td>9</td>\n",
       "      <td>143</td>\n",
       "      <td>joe biden</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>biden</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>-0.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1217941258351644673</td>\n",
       "      <td>2020-01-16 17:46:38</td>\n",
       "      <td>EST</td>\n",
       "      <td>Obama, Biden, Comey, etc. discussed the Clinto...</td>\n",
       "      <td>50434327</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "      <td>148</td>\n",
       "      <td>joe biden</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>biden</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>0.2304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                date timezone  \\\n",
       "12   1217957258467979265 2020-01-16 18:50:13      EST   \n",
       "53   1217948461443747840 2020-01-16 18:15:16      EST   \n",
       "63   1217947245955383296 2020-01-16 18:10:26      EST   \n",
       "64   1217947054850310145 2020-01-16 18:09:40      EST   \n",
       "82   1217944574951329795 2020-01-16 17:59:49      EST   \n",
       "90   1217943813118926849 2020-01-16 17:56:48      EST   \n",
       "95   1217943377674743808 2020-01-16 17:55:04      EST   \n",
       "104  1217942504110202883 2020-01-16 17:51:35      EST   \n",
       "106  1217942314934554624 2020-01-16 17:50:50      EST   \n",
       "115  1217941258351644673 2020-01-16 17:46:38      EST   \n",
       "\n",
       "                                                 tweet          user_id_str  \\\n",
       "12   Still talking about the Warren fib/lie/misunde...             20479813   \n",
       "53   Trump & Giuliani attempted to manufacture an i...             18382184   \n",
       "63   BREAKING: \"Coup Update: Senate must let Presid...             18247062   \n",
       "64   Dear USA,     We dont like your President, can...   824472044913983488   \n",
       "82   New: It looks like Ihor Kolomoisky used Lev Pa...           1489840663   \n",
       "90   \"Is She (Pelosi) trying to payback President @...             56561449   \n",
       "95                     Harris on Biden Testifying 👇  …             41634520   \n",
       "104  Warren and Biden both backed it.Schumer Praise...   829715365223682048   \n",
       "106  Today its Ukraine , GAO , Parmas , Giuliani , ...  1083551928821448710   \n",
       "115  Obama, Biden, Comey, etc. discussed the Clinto...             50434327   \n",
       "\n",
       "     likes  replies  retweets     search near geo source candidate     ratio  \\\n",
       "12     534      107       114  joe biden                     biden  0.200375   \n",
       "53     690       17       175  joe biden                     biden  0.024638   \n",
       "63    1028       36       454  joe biden                     biden  0.035019   \n",
       "64     215        6       120  joe biden                     biden  0.027907   \n",
       "82     257        9       153  joe biden                     biden  0.035019   \n",
       "90    2826      219       896  joe biden                     biden  0.077495   \n",
       "95     575      268       189  joe biden                     biden  0.466087   \n",
       "104    381       12       107  joe biden                     biden  0.031496   \n",
       "106    270        9       143  joe biden                     biden  0.033333   \n",
       "115    113        5       148  joe biden                     biden  0.044248   \n",
       "\n",
       "     sentiment  \n",
       "12     -0.5610  \n",
       "53      0.0000  \n",
       "63     -0.4926  \n",
       "64      0.2686  \n",
       "82      0.3612  \n",
       "90      0.0000  \n",
       "95      0.0000  \n",
       "104    -0.4404  \n",
       "106    -0.0772  \n",
       "115     0.2304  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.retweets>93].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a series of functions that are already part of the NLTK package. I made them before knowing that and leaving them here to understand the process of tokenizing, vectorizing, and calculating TF-IDF (scikit-learn will be used for that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweets(can_df):\n",
    "    tokens = []\n",
    "    for i,row in tqdm(can_df.iterrows()):\n",
    "        tokens.append(row['tweet'].lower().split(' '))\n",
    "    return [x for y in tokens for x in y]\n",
    "\n",
    "## The tweets are not as clean as they could be -- punctuation should be removed\n",
    "def clean_tweets(words):\n",
    "    punct = ['.',',',\"'\",\"?\",\"!\",\";\",'(',')','\"']\n",
    "    for i in range(len(words)):\n",
    "        for char in words[i]:\n",
    "            if char in punct:\n",
    "                words[i] = words[i].replace(char,'')\n",
    "    return words\n",
    "\n",
    "## vectorizing each tweet to have a count of each word -- creating bags of words\n",
    "def vectorize(tokenized_tweet):\n",
    "    unique_words = list(set(tokenized_tweet))\n",
    "    bag_o_words = {word:0 for word in unique_words}\n",
    "    for word in tokenized_tweet:\n",
    "        bag_o_words[word]+=1\n",
    "    return bag_o_words\n",
    "\n",
    "## caculates the frequency of each word over the total number of unique words\n",
    "def tf(bow):\n",
    "    total_words = sum(bow.values())\n",
    "    for word,value in bow.items():\n",
    "        bow[word] = value / total_words\n",
    "    return bow\n",
    "\n",
    "### the inverse document frequency aims to lessen the weight of words that are very frequent--like the and is\n",
    "def idf(docs):\n",
    "    vocab = set()\n",
    "    # loop list of docs and add words to vocab\n",
    "    for doc in docs:\n",
    "        for word in doc.keys():\n",
    "            vocab.add(word)\n",
    "    \n",
    "    # create dict for full vocab word frequency\n",
    "    full_vocab = {i:0 for i in vocab}\n",
    "    \n",
    "    for word, val in tqdm(full_vocab.items()):\n",
    "        count = 0\n",
    "        # loop through tweets to count words\n",
    "        for doc in docs:\n",
    "            if word in doc:\n",
    "                count += 1\n",
    "                \n",
    "        # calculate IDF\n",
    "        full_vocab[word] = np.log((len(docs)/ float(count)))\n",
    "    \n",
    "    return full_vocab\n",
    "\n",
    "## calculate td-idf for each candidate's tweets\n",
    "def tf_idf(docs):\n",
    "    doc_tf_idf = {}\n",
    "    idf_ = idf(docs)\n",
    "    full_vocab_list = {i:0 for i in idf_.keys()}\n",
    "    \n",
    "    tf_idf_list_of_dicts = []\n",
    "    \n",
    "    # Now, compute tf and then use this to compute and set tf-idf values for each document\n",
    "    for doc in tqdm(docs):\n",
    "        doc_tf = tf(doc)\n",
    "        for word in doc_tf:\n",
    "            doc_tf_idf[word] = doc_tf[word] * idf_[word]\n",
    "        tf_idf_list_of_dicts.append(doc_tf_idf)\n",
    "    \n",
    "    return tf_idf_list_of_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK for analyzing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import BigramCollocationFinder\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tool for changing words to their root word\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of words and characters to filter\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words += list(string.punctuation)\n",
    "stop_words += ['but','back','A','Im','And','If','http','It','I',\"The\",'would','its','sen','ewarren','demdebate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing is the act of putting all of the words into a list. Once we have a list of all the words, I can filter through the list using our stop_words list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 455952/455952 [00:11<00:00, 40818.27it/s]\n"
     ]
    }
   ],
   "source": [
    "## using regex to do an initial filtering of random characters\n",
    "all_tokens = []\n",
    "for tweet in tqdm(list(df['tweet'])):\n",
    "    all_tokens.extend(nltk.regexp_tokenize(pattern=\"([a-zA-Z]+(?:'[a-z]+)?)\",text=tweet.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455952, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">likes</th>\n",
       "      <th colspan=\"2\" halign=\"left\">replies</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ratio</th>\n",
       "      <th colspan=\"8\" halign=\"left\">sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>candidate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>biden</td>\n",
       "      <td>146117.0</td>\n",
       "      <td>793.420656</td>\n",
       "      <td>7834.767888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>1911685.0</td>\n",
       "      <td>146117.0</td>\n",
       "      <td>66.213076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120567</td>\n",
       "      <td>22.909091</td>\n",
       "      <td>146117.0</td>\n",
       "      <td>0.015329</td>\n",
       "      <td>0.488072</td>\n",
       "      <td>-0.9995</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanders</td>\n",
       "      <td>184140.0</td>\n",
       "      <td>889.374471</td>\n",
       "      <td>5554.406908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>905419.0</td>\n",
       "      <td>184140.0</td>\n",
       "      <td>52.143157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>23.875000</td>\n",
       "      <td>184140.0</td>\n",
       "      <td>0.074586</td>\n",
       "      <td>0.484364</td>\n",
       "      <td>-0.9988</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4671</td>\n",
       "      <td>0.9974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>warren</td>\n",
       "      <td>125695.0</td>\n",
       "      <td>571.139703</td>\n",
       "      <td>3378.443069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>182548.0</td>\n",
       "      <td>125695.0</td>\n",
       "      <td>43.621624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>34.195122</td>\n",
       "      <td>125695.0</td>\n",
       "      <td>0.057584</td>\n",
       "      <td>0.480651</td>\n",
       "      <td>-0.9992</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.9950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              likes                                                    \\\n",
       "              count        mean          std  min   25%    50%    75%   \n",
       "candidate                                                               \n",
       "biden      146117.0  793.420656  7834.767888  0.0  34.0  116.0  301.0   \n",
       "sanders    184140.0  889.374471  5554.406908  0.0   8.0  164.0  417.0   \n",
       "warren     125695.0  571.139703  3378.443069  0.0   9.0   74.0  215.0   \n",
       "\n",
       "                       replies             ...     ratio            sentiment  \\\n",
       "                 max     count       mean  ...       75%        max     count   \n",
       "candidate                                  ...                                  \n",
       "biden      1911685.0  146117.0  66.213076  ...  0.120567  22.909091  146117.0   \n",
       "sanders     905419.0  184140.0  52.143157  ...  0.090909  23.875000  184140.0   \n",
       "warren      182548.0  125695.0  43.621624  ...  0.107143  34.195122  125695.0   \n",
       "\n",
       "                                                                    \n",
       "               mean       std     min     25%  50%     75%     max  \n",
       "candidate                                                           \n",
       "biden      0.015329  0.488072 -0.9995 -0.3612  0.0  0.4019  0.9995  \n",
       "sanders    0.074586  0.484364 -0.9988 -0.2732  0.0  0.4671  0.9974  \n",
       "warren     0.057584  0.480651 -0.9992 -0.2960  0.0  0.4404  0.9950  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['candidate']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this token function will be utilized when tokenizing tweets by candidate name\n",
    "def tokenize(df, can):\n",
    "    word_tokens = []\n",
    "    for tweet in tqdm(list(df[df.candidate==can]['tweet'])):\n",
    "        word_tokens.extend(nltk.regexp_tokenize(pattern=\"([a-zA-Z]+(?:'[a-z]+)?)\",text=tweet.lower()))\n",
    "    return word_tokens\n",
    "\n",
    "def remove_stopwords(tokens,stop):\n",
    "    return [token for token in tqdm(tokens) if not token in stop]\n",
    "\n",
    "def lemmatizing(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tqdm(tokens)]\n",
    "\n",
    "''' Bigrams are a list of words and the word that follows. The function below takes in the tokens\n",
    "    utilizes the NLTK BigramFinder, and calculates a normalized weight according to how frequent \n",
    "    the bigram appears in the tweets \n",
    "'''\n",
    "def bigram_scores(tokens):\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    finder = BigramCollocationFinder.from_words(tokens)\n",
    "    return finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a list of all the filtered words\n",
    "all_filtered = [token for token in all_tokens if not token in stop_words]\n",
    "\n",
    "## lemmatizing the filtered list\n",
    "all_lemmatized = [lemmatizer.lemmatize(token) for token in all_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = bigram_scores(all_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top issues\n",
    "To find out the top issues people are talking about, I created a list of words that are associated with popular issues. The function below iterates through all the bigrams and their weights. If one of the words of the bigram are in the list of issues, that word is added to the dictionary and the weight of the bigram is added to the value of the word. The end result is the sum of the weights for each issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_issues(scores,issues):\n",
    "    top = {}\n",
    "    for item in scores:\n",
    "        top[item[0][0]] = 0\n",
    "        top[item[0][1]] = 0\n",
    "    for words in scores:\n",
    "        if words[0][0] in issues:\n",
    "            top[words[0][0]] += words[1] ## if the word in the bigram is an issue, add the bigram weight\n",
    "        if words[0][1] in issues:\n",
    "            top[words[0][1]] += words[1]\n",
    "    return {k:v for k,v in top.items() if v > 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_issues_all = top_issues(all_scores,issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'health': 0.0017087317071023834,\n",
       " 'social': 0.0013667423892571454,\n",
       " 'security': 0.001182080306441948,\n",
       " 'debt': 0.0010162488965453594,\n",
       " 'gun': 0.0009172360034569309,\n",
       " 'school': 0.0011058464531744914,\n",
       " 'military': 0.0007337888027655488,\n",
       " 'china': 0.0007829915287788003,\n",
       " 'inequality': 0.00023568713201409992,\n",
       " 'defense': 0.0004154896863341342,\n",
       " 'cannabis': 4.6469241234739506e-05,\n",
       " 'immigrate': 2.4297642475680716e-06}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_issues_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to tokenize, filter, lemmatize tweets grouped by candidate name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184140/184140 [00:04<00:00, 42422.31it/s]\n",
      "100%|██████████| 146117/146117 [00:03<00:00, 37525.90it/s]\n",
      "100%|██████████| 125695/125695 [00:03<00:00, 41173.92it/s]\n"
     ]
    }
   ],
   "source": [
    "bernie_tokens = tokenize(df,'sanders')\n",
    "joey_tokens = tokenize(df,'biden')\n",
    "lizzy_tokens = tokenize(df,'warren')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4428397/4428397 [00:15<00:00, 289802.17it/s]\n",
      "100%|██████████| 3877567/3877567 [00:13<00:00, 279837.72it/s]\n",
      "100%|██████████| 3116043/3116043 [00:11<00:00, 281818.69it/s]\n"
     ]
    }
   ],
   "source": [
    "bernie_filtered = remove_stopwords(bernie_tokens, stop_words)\n",
    "joey_filtered = remove_stopwords(joey_tokens, stop_words)\n",
    "lizzy_filtered = remove_stopwords(lizzy_tokens, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2536367/2536367 [00:20<00:00, 120892.09it/s]\n",
      "100%|██████████| 2246485/2246485 [00:17<00:00, 127986.34it/s]\n",
      "100%|██████████| 1802149/1802149 [00:15<00:00, 114704.99it/s]\n"
     ]
    }
   ],
   "source": [
    "bernie_lemmatized = lemmatizing(bernie_filtered)\n",
    "joey_lemmatized = lemmatizing(joey_filtered)\n",
    "lizzy_lemmatized = lemmatizing(lizzy_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bernie_scores = bigram_scores(bernie_lemmatized)\n",
    "joey_scores = bigram_scores(joey_lemmatized)\n",
    "lizzy_scores = bigram_scores(lizzy_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = ['health','social','security','inequality','debt','school','climate'\n",
    "         'energy','gun','immigrate','cannabis','military','defense','taxes','china']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernie_top = top_issues(bernie_scores,issues)\n",
    "joey_top = top_issues(joey_scores, issues)\n",
    "lizzy_top = top_issues(lizzy_scores, issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "12\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(len(joey_top))\n",
    "print(len(bernie_top))\n",
    "print(len(lizzy_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'social': 0.001302479206404702,\n",
       " 'security': 0.001515256055571304,\n",
       " 'health': 0.0010843606790163476,\n",
       " 'china': 0.0019221138801283684,\n",
       " 'military': 0.0008021420129669117,\n",
       " 'gun': 0.0008555587951844641,\n",
       " 'school': 0.0008858283051077434,\n",
       " 'debt': 0.00029557286160379284,\n",
       " 'defense': 0.0005234844657320138,\n",
       " 'inequality': 7.567377480820023e-05,\n",
       " 'cannabis': 6.766125747556736e-05,\n",
       " 'immigrate': 5.34167822175532e-06}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joey_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'health': 0.0026699606168980173,\n",
       " 'social': 0.0018491014904388444,\n",
       " 'security': 0.0012987079551184466,\n",
       " 'debt': 0.0012553388370058114,\n",
       " 'school': 0.0009068088332642384,\n",
       " 'inequality': 0.0004234402986634065,\n",
       " 'gun': 0.0008397838325447116,\n",
       " 'military': 0.0006702500071953116,\n",
       " 'defense': 0.0002838705912827304,\n",
       " 'china': 0.00019949794331814092,\n",
       " 'cannabis': 3.942647101149012e-05,\n",
       " 'immigrate': 1.5770588404596023e-06}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernie_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'health': 0.001134201445052519,\n",
       " 'debt': 0.0015781159049556624,\n",
       " 'school': 0.0016602400800377328,\n",
       " 'social': 0.0007679720156324517,\n",
       " 'security': 0.0006026138793185284,\n",
       " 'military': 0.000738007789588989,\n",
       " 'gun': 0.0011031274328593057,\n",
       " 'inequality': 0.0001709070670627125,\n",
       " 'defense': 0.00046611018289829953,\n",
       " 'china': 0.000184224500859807,\n",
       " 'cannabis': 2.9964226043462576e-05}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lizzy_top"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
